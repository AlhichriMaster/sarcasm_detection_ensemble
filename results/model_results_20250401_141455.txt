Model Evaluation Results
======================


LSTM Model Results:
--------------------------------------------------
               precision    recall  f1-score   support

Non-Sarcastic       0.84      0.85      0.85      2226
    Sarcastic       0.81      0.79      0.80      1774

     accuracy                           0.83      4000
    macro avg       0.82      0.82      0.82      4000
 weighted avg       0.83      0.83      0.83      4000


Attention Model Results:
--------------------------------------------------
               precision    recall  f1-score   support

Non-Sarcastic       0.83      0.88      0.85      2226
    Sarcastic       0.84      0.77      0.80      1774

     accuracy                           0.83      4000
    macro avg       0.83      0.82      0.83      4000
 weighted avg       0.83      0.83      0.83      4000


Transformer Model Results:
--------------------------------------------------
               precision    recall  f1-score   support

Non-Sarcastic       0.83      0.82      0.83      2226
    Sarcastic       0.78      0.79      0.79      1774

     accuracy                           0.81      4000
    macro avg       0.81      0.81      0.81      4000
 weighted avg       0.81      0.81      0.81      4000


Ensemble Model Results:
--------------------------------------------------
               precision    recall  f1-score   support

Non-Sarcastic       0.85      0.87      0.86      2226
    Sarcastic       0.83      0.80      0.82      1774

     accuracy                           0.84      4000
    macro avg       0.84      0.84      0.84      4000
 weighted avg       0.84      0.84      0.84      4000

